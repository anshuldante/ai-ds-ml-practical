{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: Evaluate results on validation set\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will use what we learned in last section to fit the best few models on the full training set and then evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "![Eval on Validation](../../img/evaluate_on_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "tr_features = pd.read_csv('../../../train_features.csv')\n",
    "tr_labels = pd.read_csv('../../../train_labels.csv')\n",
    "\n",
    "val_features = pd.read_csv('../../../val_features.csv')\n",
    "val_labels = pd.read_csv('../../../val_labels.csv')\n",
    "\n",
    "te_features = pd.read_csv('../../../test_features.csv')\n",
    "te_labels = pd.read_csv('../../../test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit best models on full training set\n",
    "\n",
    "Results from last section:\n",
    "```\n",
    "0.76 (+/-0.116) for {'max_depth': 2, 'n_estimators': 5}\n",
    "0.796 (+/-0.119) for {'max_depth': 2, 'n_estimators': 50}\n",
    "0.803 (+/-0.117) for {'max_depth': 2, 'n_estimators': 100}\n",
    "--> 0.828 (+/-0.074) for {'max_depth': 10, 'n_estimators': 5}\n",
    "0.816 (+/-0.028) for {'max_depth': 10, 'n_estimators': 50}\n",
    "--> 0.826 (+/-0.046) for {'max_depth': 10, 'n_estimators': 100}\n",
    "0.785 (+/-0.106) for {'max_depth': 20, 'n_estimators': 5}\n",
    "0.813 (+/-0.027) for {'max_depth': 20, 'n_estimators': 50}\n",
    "0.809 (+/-0.029) for {'max_depth': 20, 'n_estimators': 100}\n",
    "0.794 (+/-0.04) for {'max_depth': None, 'n_estimators': 5}\n",
    "0.809 (+/-0.037) for {'max_depth': None, 'n_estimators': 50}\n",
    "--> 0.818 (+/-0.035) for {'max_depth': None, 'n_estimators': 100}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=5, max_depth=10)\n",
    "rf1.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rf2.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
    "rf3.fit(tr_features, tr_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models on validation set\n",
    "\n",
    "![Evaluation Metrics](../../img/eval_metrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: 10 / # OF EST: 5 -- A: 0.771 / P: 0.727 / R: 0.737\n",
      "MAX DEPTH: 10 / # OF EST: 100 -- A: 0.827 / P: 0.869 / R: 0.697\n",
      "MAX DEPTH: None / # OF EST: 100 -- A: 0.816 / P: 0.831 / R: 0.711\n"
     ]
    }
   ],
   "source": [
    "for mdl in [rf1, rf2, rf3]:\n",
    "    y_pred = mdl.predict(val_features)\n",
    "    accuracy = round(accuracy_score(val_labels, y_pred), 3)\n",
    "    precision = round(precision_score(val_labels, y_pred), 3)\n",
    "    recall = round(recall_score(val_labels, y_pred), 3)\n",
    "    print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(mdl.max_depth,\n",
    "                                                                         mdl.n_estimators,\n",
    "                                                                         accuracy,\n",
    "                                                                         precision,\n",
    "                                                                         recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best model on the test set\n",
    "\n",
    "![Final Model](../../img/final_model_selection.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-100d1711e7bd>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-100d1711e7bd>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    accuracy = round(, 3)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf2.predict()\n",
    "accuracy = round(, 3)\n",
    "precision = round(, 3)\n",
    "recall = round(, 3)\n",
    "print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(rf2.max_depth,\n",
    "                                                                     rf2.n_estimators,\n",
    "                                                                     accuracy,\n",
    "                                                                     precision,\n",
    "                                                                     recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
